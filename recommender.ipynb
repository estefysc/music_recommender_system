{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_df = pd.read_csv('data/spotify_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['acoustic', 'acoustic', 'acoustic', ..., 'trip-hop', 'trip-hop',\n",
       "       'trip-hop'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if this is a list or a string that looks like a list\n",
    "spotify_df['genre'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['danceability', 'energy', 'loudness', 'speechiness', 'acousticness',\n",
      "       'instrumentalness', 'liveness', 'valence', 'tempo'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "float_cols = spotify_df.dtypes[spotify_df.dtypes == 'float64'].index\n",
    "print(float_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_cols = 'popularity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change display options to avoid scientific notation\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "# describe(): This method is used to generate descriptive statistics that summarize the central tendency, dispersion, \n",
    "# and shape of a dataset’s distribution, excluding NaN values. \n",
    "spotify_df['popularity'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a new column popularity_transform by scaling down the values of the popularity column and converting them to integers. \n",
    "# Each original popularity score is divided by 5, and the result is truncated to an integer. \n",
    "spotify_df['popularity_transform'] = spotify_df['popularity'].apply(lambda x: int(x / 5))\n",
    "\n",
    "# Get the position of the 'popularity' column\n",
    "popularity_index = spotify_df.columns.get_loc('popularity')\n",
    "\n",
    "# Insert the 'popularity_transform' column next to the 'popularity' column\n",
    "spotify_df.insert(popularity_index + 1, 'popularity_transform', spotify_df.pop('popularity_transform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since tfidf cannot handle nulls, check if there are any null values in the entire DataFrame\n",
    "any_null = spotify_df.isnull().values.any()\n",
    "print(f\"Any null values in DataFrame: {any_null}\")\n",
    "\n",
    "# Count of null values in each column\n",
    "null_counts = spotify_df.isnull().sum()\n",
    "print(\"\\nCount of null values in each column:\")\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_df['artist_name'] = spotify_df['artist_name'].apply(lambda d: d if isinstance(d, str) else '')\n",
    "spotify_df['track_name'] = spotify_df['track_name'].apply(lambda d: d if isinstance(d, str) else '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we eliminated the null values\n",
    "any_null = spotify_df.isnull().values.any()\n",
    "print(f\"Any null values in DataFrame: {any_null}\")\n",
    "\n",
    "# Count of null values in each column\n",
    "null_counts = spotify_df.isnull().sum()\n",
    "print(\"\\nCount of null values in each column:\")\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_one_hot_encoded_features(df, column, new_name): \n",
    "    \"\"\" \n",
    "    Create One Hot Encoded features for a specific column in the DataFrame.\n",
    "\n",
    "    This function takes a specified column from the DataFrame, applies one-hot encoding to convert categorical values into a binary matrix, \n",
    "    and renames the resulting columns with a new prefix. The new columns will be prefixed with the provided new_name, followed by the original column value.\n",
    "\n",
    "    Parameters: \n",
    "        df (pandas.DataFrame): The input DataFrame containing the data.\n",
    "        column (str): The name of the column to be one-hot encoded.\n",
    "        new_name (str): The prefix to be used for the new one-hot encoded columns.\n",
    "        \n",
    "    Returns: \n",
    "        pandas.DataFrame: A DataFrame containing the one-hot encoded features with the new column names.\n",
    "    \"\"\"\n",
    "\n",
    "    # Apply one-hot encoding to the specified column\n",
    "    transformed_df = pd.get_dummies(df[column])\n",
    "\n",
    "    # Get the names of the newly created one-hot encoded columns\n",
    "    feature_names = transformed_df.columns\n",
    "\n",
    "    # Rename the columns with the new prefix\n",
    "    transformed_df.columns = [new_name + \"|\" + str(i) for i in feature_names]\n",
    "\n",
    "    # Reset the index of the DataFrame\n",
    "    transformed_df.reset_index(drop = True, inplace = True)   \n",
    "     \n",
    "    return transformed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term Frequency Inverse Document Frequency. This is very common algorithm to transform text into a meaningful representation of numbers which is used to fit machine algorithm for prediction. It is a statistical formula to convert text documents into vectors based on the relevancy of the word. It is based on the bag of the words model to create a matrix containing the information about less relevant and most relevant words in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build entire feature set\n",
    "def create_feature_set(df, float_cols):\n",
    "    \"\"\" \n",
    "    Process Spotify DataFrame to create a final set of features for generating recommendations.\n",
    "\n",
    "    This function performs several steps to preprocess the given DataFrame and generate a set of features that can be used for building a recommendation system. The steps include:\n",
    "    1. Formatting the 'genre' column.\n",
    "    2. Applying TF-IDF vectorization to the 'genre' column to convert text data into numerical features.\n",
    "    3. One-hot encoding the 'year' and 'popularity_transform' columns.\n",
    "    4. Scaling specified float columns.\n",
    "    5. Concatenating all processed features into a single DataFrame.\n",
    "    6. Adding the 'track_id' column to maintain track identifiers.\n",
    "\n",
    "    Parameters: \n",
    "        df (pandas.DataFrame): The Spotify DataFrame containing track data.\n",
    "        float_cols (list of str): List of columns with float values that need to be scaled.\n",
    "\n",
    "    Returns: \n",
    "        pandas.DataFrame: A DataFrame containing the final set of features for each track.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure 'genre' column is properly formatted as a string\n",
    "    df['genre'] = df['genre'].apply(lambda x: str(x) if isinstance(x, str) else '')\n",
    "    \n",
    "    # Apply TF-IDF Vectorizer to the 'genre' column\n",
    "    tfidf = TfidfVectorizer()\n",
    "    processed_genres = df['genre']\n",
    "\n",
    "    # Check for empty genre documents after preprocessing\n",
    "    if processed_genres.str.strip().eq('').any():\n",
    "        raise ValueError(\"Some documents are empty after preprocessing. Check the 'genre' column.\")\n",
    "\n",
    "    # Transform genres into TF-IDF features\n",
    "    tfidf_matrix = tfidf.fit_transform(processed_genres)\n",
    "    genre_df = pd.DataFrame(tfidf_matrix.toarray())\n",
    "    genre_df.columns = ['genre' + \"|\" + i for i in tfidf.get_feature_names_out()]\n",
    "    genre_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # One-hot encode the 'year' and 'popularity_transform' columns, scaling their impact\n",
    "    year_ohe = create_one_hot_encoded_features(df, 'year','year') * 0.5\n",
    "    popularity_ohe = create_one_hot_encoded_features(df, 'popularity_transform','pop') * 0.15\n",
    "\n",
    "    # Scale specified float columns\n",
    "    floats = df[float_cols].reset_index(drop = True)\n",
    "    scaler = MinMaxScaler()\n",
    "    floats_scaled = pd.DataFrame(scaler.fit_transform(floats), columns = floats.columns) * 0.2\n",
    "\n",
    "    # Concatenate all features into a single DataFrame\n",
    "    final_df = pd.concat([genre_df, floats_scaled, popularity_ohe, year_ohe], axis = 1)\n",
    "     \n",
    "    # Add the 'track_id' to the final DataFrame\n",
    "    final_df['track_id'] = df['track_id'].values\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_feature_set = create_feature_set(spotify_df, float_cols = float_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_feature_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spotify API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import spotipy\n",
    "import spotipy.util as util\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from spotipy.oauth2 import SpotifyPKCE\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()  \n",
    "\n",
    "spotify_client_id = os.getenv('CLIENT_ID')\n",
    "spotify_client_secret = os.getenv('CLIENT_SECRET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The set of scopes you set during the authorization, determines the access permissions that the user is asked to grant.\n",
    "# scope = \"playlist-read-private playlist-modify-private playlist-modify-public user-read-playback-position user-top-read user-read-recently-played user-library-read\"\n",
    "scope = [\"user-library-read\", \"playlist-read-private\", \"playlist-modify-private\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(sys.argv) > 1:\n",
    "    username = sys.argv[1]\n",
    "else:\n",
    "    print(\"Usage: %s username\" % (sys.argv[0],))\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Authorization Code with PKCE since I will not be using a server. I will have to implement Authorization Code with PKCE if I want\n",
    "# to expose this in a web app.\n",
    " \n",
    "# PKCE\n",
    "# __init__(client_id=None, redirect_uri=None, state=None, scope=None, cache_path=None, username=None, proxies=None, \n",
    "#          requests_timeout=None, requests_session=True, open_browser=True, cache_handler=None)\n",
    "# auth_manager = SpotifyPKCE(spotify_client_id, 'https://localhost:8888/callback', scope=scope)\n",
    "\n",
    "auth_manager = SpotifyOAuth(spotify_client_id, spotify_client_secret, 'https://localhost:8888/callback', scope=scope, show_dialog=True)\n",
    "# Generate the authorization URL\n",
    "auth_url = auth_manager.get_authorize_url()\n",
    "\n",
    "# Open the authorization URL in the default browser\n",
    "print(f'Please navigate to the following URL to authorize the application: {auth_url}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually enter the full redirected URL after authorization\n",
    "redirected_url = input(\"\")\n",
    "\n",
    "# Extract the authorization code from the URL\n",
    "code = auth_manager.parse_response_code(redirected_url)\n",
    "\n",
    "# Obtain the access token using the authorization code\n",
    "token_info = auth_manager.get_access_token(code)\n",
    "\n",
    "# Initialize Spotify client with the access token\n",
    "sp = spotipy.Spotify(auth=token_info['access_token'])\n",
    "\n",
    "# token = util.prompt_for_user_token(scope, client_id=spotify_client_id, client_secret=spotify_client_secret, redirect_uri='https://localhost:8888/callback')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The authorization code flow is suitable for long-running applications (e.g. web and mobile apps) where the user grants permission only once.\n",
    "# If you’re using the authorization code flow in a mobile app, or any other type of application where the client secret can't be safely stored, then you should use the PKCE extension.\n",
    "# This flow is required for accessing user-specific data, such as the user's library, playlists, and other private data that the user has given permission to access.\n",
    "\n",
    "# sp = spotipy.Spotify(auth=token)\n",
    "\n",
    "# Note: Both types of authentication are not needed on an actual app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather playlists names and images\n",
    "\n",
    "id_name = {}\n",
    "list_photo = {}\n",
    "\n",
    "for i in sp.current_user_playlists(50)['items']:\n",
    "    # print(i)\n",
    "    id_name[i['name']] = i['uri'].split(':')[2]\n",
    "    list_photo[i['uri'].split(':')[2]] = i['images'][0]['url']\n",
    "\n",
    "id_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_playlist_dataframe(playlist_name, id_dic, df):\n",
    "    \"\"\"\n",
    "    This function retrieves songs from a specified playlist using the Spotify API, filters the songs to include only those available in \n",
    "    the provided Kaggle dataset, and returns the filtered playlist. The resulting playlist DataFrame includes artist names, track names, track IDs, \n",
    "    album image URLs, and the dates when the tracks were added to the playlist.\n",
    "\n",
    "    Parameters: \n",
    "        playlist_name (str): The name of the playlist to pull from the Spotify API.\n",
    "        id_dic (dict): A dictionary mapping playlist names to their corresponding playlist IDs.\n",
    "        df (pandas.DataFrame): The DataFrame containing the Kaggle dataset with track information.\n",
    "        \n",
    "    Returns: \n",
    "        pandas.DataFrame: A DataFrame containing all songs in the specified playlist that are available in the Kaggle dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize an empty DataFrame for the playlist\n",
    "    playlist = pd.DataFrame()\n",
    "\n",
    "    # Retrieve tracks from the specified playlist using the Spotify API\n",
    "    for index, i in enumerate(sp.playlist(id_dic[playlist_name])['tracks']['items']):\n",
    "\n",
    "        # Extract and assign track details to the DataFrame\n",
    "        playlist.loc[index, 'artist'] = i['track']['artists'][0]['name']\n",
    "        playlist.loc[index, 'name'] = i['track']['name']\n",
    "        playlist.loc[index, 'id'] = i['track']['id']\n",
    "        playlist.loc[index, 'url'] = i['track']['album']['images'][1]['url']\n",
    "        playlist.loc[index, 'date_added'] = i['added_at']\n",
    "\n",
    "    # Convert the 'date_added' column to datetime format\n",
    "    playlist['date_added'] = pd.to_datetime(playlist['date_added'])\n",
    "\n",
    "    # Rename the 'id' column to 'track_id'\n",
    "    playlist.rename(columns={'id': 'track_id'}, inplace=True)\n",
    "\n",
    "    # Filter the playlist to include only songs that are available in the Kaggle dataset\n",
    "    playlist = playlist[playlist['track_id'].isin(df['track_id'].values)].sort_values('date_added', ascending=False)\n",
    "    \n",
    "    return playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_liked_songs_dataframe(spotify_data, limit=50):\n",
    "    \"\"\"\n",
    "    This function retrieves the user's liked songs using the Spotify API. The function filters the songs to include only those available in \n",
    "    the provided Kaggle dataset, and returns the filtered playlist. The resulting playlist DataFrame includes artist names, track names, track IDs, \n",
    "    album image URLs, and the dates when the tracks were added to the playlist.\n",
    "\n",
    "    Parameters: \n",
    "        spotify_data (pandas.DataFrame): The DataFrame containing the Kaggle dataset with track information.\n",
    "        limit (int): The maximum number of songs to retrieve from the user's liked songs playlist. The maximum limit is 50 per call.\n",
    "        \n",
    "    Returns: \n",
    "        pandas.DataFrame: A DataFrame containing all songs in the specified playlist that are available in the Kaggle dataset.\n",
    "    \"\"\"\n",
    "    # Initialize an empty DataFrame for the playlist\n",
    "    playlist = pd.DataFrame()\n",
    "    offset = 0\n",
    "    tracks = []\n",
    "\n",
    "    while True:\n",
    "        response = sp.current_user_saved_tracks(limit=limit, offset=offset)\n",
    "        items = response['items']\n",
    "\n",
    "        if not items:\n",
    "            break\n",
    "\n",
    "        tracks.extend(items)\n",
    "        offset += len(items)\n",
    "    \n",
    "    # Retrieve \"liked\" tracks from the specified playlist using the Spotify API\n",
    "    # The maximum songs it can retrieve is 50\n",
    "    \n",
    "    for index, i in enumerate(tracks):\n",
    "        # Extract and assign track details to the DataFrame\n",
    "        playlist.loc[index, 'artist'] = i['track']['artists'][0]['name']\n",
    "        playlist.loc[index, 'name'] = i['track']['name']\n",
    "        playlist.loc[index, 'id'] = i['track']['id']\n",
    "        playlist.loc[index, 'url'] = i['track']['album']['images'][1]['url']\n",
    "        playlist.loc[index, 'date_added'] = i['added_at']\n",
    "\n",
    "    # Convert the 'date_added' column to datetime format\n",
    "    playlist['date_added'] = pd.to_datetime(playlist['date_added'])\n",
    "\n",
    "    # Rename the 'id' column to 'track_id'\n",
    "    playlist.rename(columns={'id': 'track_id'}, inplace=True)\n",
    "\n",
    "    # Filter the playlist to include only songs that are available in the Kaggle dataset\n",
    "    playlist = playlist[playlist['track_id'].isin(spotify_data['track_id'].values)].sort_values('date_added', ascending=False)\n",
    "    \n",
    "    return playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "liked_songs = create_liked_songs_dataframe(spotify_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 5)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liked_songs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>name</th>\n",
       "      <th>track_id</th>\n",
       "      <th>url</th>\n",
       "      <th>date_added</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stephen Sanchez</td>\n",
       "      <td>Until I Found You (with Em Beihold) - Em Beiho...</td>\n",
       "      <td>1Y3LN4zO1Edc2EluIoSPJN</td>\n",
       "      <td>https://i.scdn.co/image/ab67616d00001e022bf087...</td>\n",
       "      <td>2024-05-26 17:13:47+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>Save Your Tears (with Ariana Grande) (Remix)</td>\n",
       "      <td>37BZB0z9T8Xu7U3e65qxFy</td>\n",
       "      <td>https://i.scdn.co/image/ab67616d00001e02c6af5f...</td>\n",
       "      <td>2024-03-22 19:20:52+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Maná</td>\n",
       "      <td>Mi Verdad (feat. Shakira)</td>\n",
       "      <td>3YmA3gZqlXl0MkwhkVKxRy</td>\n",
       "      <td>https://i.scdn.co/image/ab67616d00001e02e7b7c3...</td>\n",
       "      <td>2023-10-19 15:58:30+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Patrick Watson</td>\n",
       "      <td>Je te laisserai des mots</td>\n",
       "      <td>0V5cvmTKsYmF5FmGGEAfmS</td>\n",
       "      <td>https://i.scdn.co/image/ab67616d00001e02de9b00...</td>\n",
       "      <td>2023-10-03 20:09:09+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Black Eyed Peas</td>\n",
       "      <td>MAMACITA</td>\n",
       "      <td>14wf185UxfNbSy8dwt4r4q</td>\n",
       "      <td>https://i.scdn.co/image/ab67616d00001e029d1572...</td>\n",
       "      <td>2023-10-02 15:12:28+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             artist                                               name  \\\n",
       "0   Stephen Sanchez  Until I Found You (with Em Beihold) - Em Beiho...   \n",
       "17       The Weeknd       Save Your Tears (with Ariana Grande) (Remix)   \n",
       "28             Maná                          Mi Verdad (feat. Shakira)   \n",
       "30   Patrick Watson                           Je te laisserai des mots   \n",
       "31  Black Eyed Peas                                           MAMACITA   \n",
       "\n",
       "                  track_id                                                url  \\\n",
       "0   1Y3LN4zO1Edc2EluIoSPJN  https://i.scdn.co/image/ab67616d00001e022bf087...   \n",
       "17  37BZB0z9T8Xu7U3e65qxFy  https://i.scdn.co/image/ab67616d00001e02c6af5f...   \n",
       "28  3YmA3gZqlXl0MkwhkVKxRy  https://i.scdn.co/image/ab67616d00001e02e7b7c3...   \n",
       "30  0V5cvmTKsYmF5FmGGEAfmS  https://i.scdn.co/image/ab67616d00001e02de9b00...   \n",
       "31  14wf185UxfNbSy8dwt4r4q  https://i.scdn.co/image/ab67616d00001e029d1572...   \n",
       "\n",
       "                  date_added  \n",
       "0  2024-05-26 17:13:47+00:00  \n",
       "17 2024-03-22 19:20:52+00:00  \n",
       "28 2023-10-19 15:58:30+00:00  \n",
       "30 2023-10-03 20:09:09+00:00  \n",
       "31 2023-10-02 15:12:28+00:00  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liked_songs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_user_playlist = create_playlist_dataframe('Classical', id_name, spotify_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_songs(df):\n",
    "    \"\"\" \n",
    "    Visualize cover art of the songs in the inputted DataFrame.\n",
    "\n",
    "    This function takes a DataFrame containing song details, specifically URLs to cover art images, and visualizes these images in a grid \n",
    "    format. Each image is displayed along with the song name as a label below it. The grid is dynamically sized based on the number of songs in the DataFrame.\n",
    "\n",
    "    Parameters: \n",
    "        df (pandas.DataFrame): A DataFrame containing playlist information, including a column 'url' with URLs to the cover art images and a column 'name' with the song names.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract URLs of cover art images from the DataFrame\n",
    "    temp = df['url'].values\n",
    "\n",
    "    # Create a figure with a dynamic height based on the number of images\n",
    "    plt.figure(figsize=(15, int(0.625 * len(temp))))\n",
    "\n",
    "    # Define the number of columns for the grid layout\n",
    "    columns = 5\n",
    "    \n",
    "    # Loop through each URL and plot the corresponding image\n",
    "    for index, url in enumerate(temp):\n",
    "        # Create a subplot for each image\n",
    "        plt.subplot(int(len(temp) / columns + 1), columns, index + 1)\n",
    "\n",
    "        # Read the image from the URL\n",
    "        image = io.imread(url)\n",
    "\n",
    "        # Display the image\n",
    "        plt.imshow(image)\n",
    "        \n",
    "        # Remove axis ticks for a cleaner look\n",
    "        plt.xticks(color='w', fontsize=0.1)\n",
    "        plt.yticks(color='w', fontsize=0.1)\n",
    "\n",
    "        # Add the song name as a label below the image\n",
    "        plt.xlabel(df['name'].values[index], fontsize=10)\n",
    "\n",
    "        # Adjust layout for better spacing\n",
    "        plt.tight_layout(h_pad=0.4, w_pad=0)\n",
    "        plt.subplots_adjust(wspace=None, hspace=None)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_songs(liked_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_playlist_feature_vector(complete_feature_set, playlist_df, decay_factor):\n",
    "    \"\"\" \n",
    "    Summarize a user's playlist into a single vector.\n",
    "\n",
    "    This function processes a user's playlist to create a summarized feature vector that represents the playlist. \n",
    "    It applies a recency bias to give more weight to recently added songs. The function also returns a DataFrame of songs that are not \n",
    "    in the user's playlist for potential further analysis or recommendations.\n",
    "\n",
    "    Parameters: \n",
    "        complete_feature_set (pandas.DataFrame): DataFrame containing all features for the Spotify songs.\n",
    "        playlist_df (pandas.DataFrame): DataFrame containing the user's playlist information.\n",
    "        decay_factor (float): A float value representing the decay_factor for the recency bias. The lower the value, the less importance older songs will have.\n",
    "        \n",
    "    Returns: \n",
    "        pandas.Series: A single feature vector that summarizes the playlist.\n",
    "        pandas.DataFrame: A DataFrame containing songs not in the user's playlist.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filter the complete feature set to include only the songs in the user's playlist\n",
    "    complete_feature_set_playlist = complete_feature_set[complete_feature_set['track_id'].isin(playlist_df['track_id'].values)]\n",
    "    \n",
    "    # Merge with playlist DataFrame to include the date added information\n",
    "    complete_feature_set_playlist = complete_feature_set_playlist.merge(playlist_df[['track_id', 'date_added']], on='track_id', how='inner')\n",
    "    \n",
    "    # Create a DataFrame containing songs not in the user's playlist\n",
    "    complete_feature_set_nonplaylist = complete_feature_set[~complete_feature_set['track_id'].isin(playlist_df['track_id'].values)]\n",
    "    \n",
    "    # Sort the playlist feature set by date added in descending order\n",
    "    playlist_feature_set = complete_feature_set_playlist.sort_values('date_added', ascending=False)\n",
    "\n",
    "    # Get the date of the most recently added song\n",
    "    most_recent_date = playlist_feature_set.iloc[0, -1]\n",
    "    \n",
    "    # Calculate the number of months from the most recent date for each song in the playlist\n",
    "    for index, row in playlist_feature_set.iterrows():\n",
    "        playlist_feature_set.loc[index, 'months_from_recent'] = int((most_recent_date.to_pydatetime() - row['date_added'].to_pydatetime()).days / 30)\n",
    "        \n",
    "    # Apply an exponential decay function to set the weights (mimics recency bias)\n",
    "    playlist_feature_set['weight'] = playlist_feature_set['months_from_recent'].apply(lambda x: decay_factor ** (x))\n",
    "    \n",
    "    # Create a weighted version of the playlist feature set\n",
    "    playlist_feature_set_weighted = playlist_feature_set.copy()\n",
    "    playlist_feature_set_weighted.update(playlist_feature_set_weighted.iloc[:, :-4].mul(playlist_feature_set_weighted['weight'], 0))\n",
    "    \n",
    "    # Exclude the last four columns (which include metadata and weights) to create the final weighted feature set\n",
    "    playlist_feature_set_weighted_final = playlist_feature_set_weighted.iloc[:, :-4]\n",
    "    \n",
    "    # Summarize the playlist into a single vector by summing the weighted features\n",
    "    return playlist_feature_set_weighted_final.sum(axis=0), complete_feature_set_nonplaylist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing the appropriate value for the decay_factor in the generate_playlist_feature_vector function depends on how much recency bias \n",
    "you want to incorporate into your recommendation system. The decay_factor determines how quickly the influence of older songs diminishes \n",
    "compared to more recently added songs. Here are some guidelines and considerations to help you choose the right value:\n",
    "\n",
    "    Value Range:\n",
    "        The decay_factor should be a value close to 1 but less than 1. Common choices are between 0.8 and 0.99. \n",
    "        This range ensures that the decay is not too rapid and maintains a reasonable influence for older songs.\n",
    "\n",
    "    Recency Emphasis:\n",
    "        Higher Values - lower recency bias (e.g., 0.95 - 0.99):\n",
    "            Slower decay of weights.\n",
    "            Older songs retain more influence.\n",
    "            Suitable if user preferences change gradually or if older songs are still relevant.\n",
    "        Lower Values - higher recency bias (e.g., 0.8 - 0.9):\n",
    "            Faster decay of weights.\n",
    "            More emphasis on recent songs.\n",
    "            Suitable if user preferences change rapidly or if you want to prioritize very recent behavior.\n",
    "\n",
    "    Domain Considerations:\n",
    "        Consider the typical listening behavior and the context of the playlist. For example, daily playlists might benefit from a \n",
    "        higher recency bias compared to long-term favorite collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_feature_set_playlist_vector, complete_feature_set_nonplaylist = generate_playlist_feature_vector(complete_feature_set, liked_songs, 0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Song Score Calculation\n",
    "\n",
    "The playlist vectors will be compared to individual song vectors using cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recommendations(spotify_data, playlist_features, nonplaylist_features):\n",
    "    \"\"\" \n",
    "    Generate song recommendations based on a user's playlist.\n",
    "\n",
    "    This function calculates the cosine similarity between the user's playlist feature vector and the feature vectors of all songs not in the playlist. \n",
    "    It then sorts the songs based on their similarity to the playlist and returns the top recommendations.\n",
    "\n",
    "    Parameters: \n",
    "        spotify_data (pandas.DataFrame): DataFrame containing all features for the Spotify songs in the Kaggle data.\n",
    "        playlist_features (pandas.Series): A single feature vector that summarizes the user's playlist.\n",
    "        nonplaylist_features (pandas.DataFrame): DataFrame containing songs not in the user's playlist.\n",
    "        \n",
    "    Returns: \n",
    "        pandas.DataFrame: A DataFrame containing the top song recommendations based on the user's playlist.\n",
    "    \"\"\"\n",
    "    def get_track_info(track_id):\n",
    "        try:\n",
    "            track_info = sp.track(track_id)\n",
    "            return track_info['album']['images'][1]['url'] if len(track_info['album']['images']) > 1 else None\n",
    "        except (IndexError, KeyError, spotipy.SpotifyException):\n",
    "            return None\n",
    "\n",
    "    nonplaylist_recommendations = spotify_data[spotify_data['track_id'].isin(nonplaylist_features['track_id'].values)]\n",
    "    nonplaylist_recommendations['similarity'] = cosine_similarity(nonplaylist_features.drop('track_id', axis=1).values, playlist_features.values.reshape(1, -1))[:,0]\n",
    "    nonplaylist_recommendations_top = nonplaylist_recommendations.sort_values('similarity', ascending=False).head(300)\n",
    "    nonplaylist_recommendations_top['url'] = nonplaylist_recommendations_top['track_id'].apply(lambda x: get_track_info(x))\n",
    "    nonplaylist_recommendations_top = nonplaylist_recommendations_top.rename(columns={'track_name': 'name'})\n",
    "\n",
    "    return nonplaylist_recommendations_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_recommendations = generate_recommendations(spotify_df, complete_feature_set_playlist_vector, complete_feature_set_nonplaylist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_songs(top_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  user_playlist_create(user, name, public=True, collaborative=False, description='')\n",
    "def create_playlist_from_recommendations(playlist_name, recommendations, batch_size=100):\n",
    "    \"\"\"\n",
    "    Add tracks to a Spotify playlist in batches.\n",
    "\n",
    "    Parameters:\n",
    "        sp (spotipy.Spotify): Spotipy client instance.\n",
    "        playlist_id (str): The ID of the playlist.\n",
    "        track_ids (list): List of track IDs to add to the playlist.\n",
    "        batch_size (int): Number of tracks to add per batch. Maximum is 100 per call.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    position = 0\n",
    "    userId = sp.me()['id']\n",
    "    new_playlist = sp.user_playlist_create(userId, playlist_name, public=False, collaborative=False, description='Playlist created by the experimental recommender system')\n",
    "    track_ids = recommendations.get('track_id').values\n",
    "    \n",
    "    # print(f\"Adding {len(track_ids)} tracks to the playlist...\")\n",
    "\n",
    "    for i in range(0, len(track_ids), batch_size):\n",
    "        batch = track_ids[i:i + batch_size]\n",
    "        sp.playlist_add_items(new_playlist['id'], batch, position=position)\n",
    "        position += len(batch)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_playlist_from_recommendations('Fresh Music', top_recommendations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recommenderVar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
